# -*- coding: utf-8 -*-
"""SML Project (AE Implementation)

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sthgWarmaVn4YVIvMFoM9sHepBLNDs06
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from matplotlib import pyplot as plt
import keras
from sklearn.manifold import TSNE
from keras.layers import Input, Dense
from keras.models import Model, Sequential
from keras import regularizers
from sklearn import preprocessing 
import itertools

data=pd.read_csv('/content/drive/My Drive/creditcard.csv')
#data["Time"] = data["Time"].apply(lambda x : x / 3600 % 24)

non_fraud = data[data['Class'] == 0]
fraud = data[data['Class'] == 1]
data = data.sample(frac=1).reset_index(drop=True)

X = data.drop(['Class','Time'], axis = 1).values
Y = data["Class"].values

#nature of representations can be learned by T-SNE Representation

X_train, X_test, y_train, y_test= train_test_split(X,Y, test_size=0.2,random_state=42)

def tsne_plot(x1, y1, name="graph.png"):
    tsne = TSNE(n_components=2, random_state=0)
    X_t = tsne.fit_transform(x1)

    plt.figure(figsize=(12, 8))
    plt.scatter(X_t[np.where(y1 == 0), 0], X_t[np.where(y1 == 0), 1], marker='o', color='g', linewidth='1', alpha=0.8, label='Non Fraud')
    plt.scatter(X_t[np.where(y1 == 1), 0], X_t[np.where(y1 == 1), 1], marker='o', color='r', linewidth='1', alpha=0.8, label='Fraud')

    plt.legend(loc='best');

    plt.show();

non_fraud=X_test[y_test==0]
fraud=X_test[y_test==1]
mod1 = np.append(non_fraud[:3000], fraud, axis = 0)
ha = np.zeros(3000)
lo = np.ones(fraud.shape[0])
mod2 = np.append(ha,lo)

tsne_plot(mod1, mod2, "original.png")

#Autoencoder for latent represenations

input_layer = Input(shape=(X_train.shape[1],))
encoded = Dense(100, activation='tanh', activity_regularizer=regularizers.l1(10e-5))(input_layer)
dd1=Dense(75,activation='tanh')(encoded)
dd2=Dense(50,activation='tanh')(dd1)
encoded1= Dense(20, activation='tanh')(dd2)
decoded1= Dense(20, activation='tanh')(encoded1)
dd11=Dense(50,activation='tanh')(decoded1)
dd22=Dense(75,activation='tanh')(dd11)
decoded2=Dense(100, activation='tanh')(dd22)
output_layer = Dense(X_train.shape[1], activation='tanh')(decoded2)

autoencoder = Model(input_layer, output_layer)
autoencoder.compile(optimizer="adam", loss="mse")

autoencoder.summary()

scaler=preprocessing.MinMaxScaler()
X_scale = scaler.fit_transform(X_train)
X_train_norm, X_train_fraud = X_scale[y_train == 0], X_scale[y_train == 1]

#Test
X_test_scale = scaler.transform(X_test)
X_test_norm, X_test_fraud = X_test_scale[y_test == 0], X_test_scale[y_test == 1]

autoencoder.fit(X_train_norm, X_train_norm, 
                batch_size = 64, epochs = 10, 
                shuffle = True, validation_split = 0.20);

#Test Autoencoder
X_Test_norm_pred=autoencoder.predict(X_test_norm)

"""**Prediction of the latent representations**"""

latent_representation = Sequential()
latent_representation.add(autoencoder.layers[0])
latent_representation.add(autoencoder.layers[1])
latent_representation.add(autoencoder.layers[2])
latent_representation.add(autoencoder.layers[3])
latent_representation.add(autoencoder.layers[4])

train_norm_hid_rep = latent_representation.predict(X_train_norm)
train_fraud_hid_rep = latent_representation.predict(X_train_fraud)

test_norm_hid_rep=latent_representation.predict(X_test_norm)
test_fraud_hid_rep=latent_representation.predict(X_test_fraud)

rep_x = np.append(train_norm_hid_rep, train_fraud_hid_rep, axis = 0)
y_n = np.zeros(train_norm_hid_rep.shape[0])
y_f = np.ones(train_fraud_hid_rep.shape[0])
rep_y = np.append(y_n, y_f)

tsne_plot(rep_x, rep_y, "latent_representation.png")

test_rep_x = np.append(test_norm_hid_rep, test_fraud_hid_rep, axis = 0)
test_y_n = np.zeros(test_norm_hid_rep.shape[0])
test_y_f = np.ones(test_fraud_hid_rep.shape[0])
test_rep_y = np.append(test_y_n, test_y_f)

tsne_plot(test_rep_x, test_rep_y, "latent_representation.png")

"""**Evaluation and results**

1. Evaluation on train data
"""

#Training of linear classifier for classifying latent representations
from sklearn.metrics import classification_report, accuracy_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
clf=LogisticRegression()
clf1=RandomForestClassifier()
clf1.fit(rep_x,rep_y)
print(classification_report(clf1.predict(rep_x),rep_y))
print ("Accuracy Score: ", accuracy_score(clf1.predict(rep_x), rep_y))

"""2. Evaluation on test data"""

test_rep_x_pred=clf1.predict(test_rep_x)

print(classification_report(clf1.predict(test_rep_x),test_rep_y))
print ("Accuracy Score: ", accuracy_score(clf1.predict(test_rep_x), test_rep_y))

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=0)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        #print("Normalized confusion matrix")
    else:
        1#print('Confusion matrix, without normalization')


    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

from sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve,recall_score,auc,accuracy_score
cnf_matrix = confusion_matrix(test_rep_x_pred,test_rep_y)
np.set_printoptions(precision=2)
print("Recall metric in the testing dataset: ", cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1]))
class_names = [0,1]
plt.figure()
plot_confusion_matrix(cnf_matrix
                      , classes=class_names
                      , title='Confusion matrix')
plt.show()

fpr, tpr, thresholds = roc_curve(test_rep_y,test_rep_x_pred)
roc_auc = auc(fpr,tpr)

# Plot ROC
plt.title('Receiver Operating Characteristic')
plt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)
plt.legend(loc='lower right')
plt.plot([0,1],[0,1],'r--')
plt.xlim([-0.1,1.0])
plt.ylim([-0.1,1.01])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

